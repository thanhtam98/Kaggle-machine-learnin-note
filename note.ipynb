{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQPaBwgaoV32"
      },
      "source": [
        "# KAGGLE MACHINE LEARNING NOTEBOOK #\n",
        "##### _Proceduce guide to solve kaggle competiton_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZZ0p-MYoV35"
      },
      "source": [
        "## 0. Preface\n",
        "<a id='1'></a>\n",
        "\n",
        "1. <b>Understand the problem</b>. We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n",
        "2. <b>Univariable study</b>. We'll just focus on the dependent variable ('SalePrice') and try to know a little bit more about it.\n",
        "3. <b>Multivariate study</b>. We'll try to understand how the dependent variable and independent variables relate.\n",
        "4. <b>Basic cleaning</b>. We'll clean the dataset and handle the missing data, outliers and categorical variables.\n",
        "5. <b>Test assumptions</b>. We'll check if our data meets the assumptions required by most multivariate techniques.\n",
        "\n",
        "### Summary\n",
        "\n",
        "[1]. <b>Exploratory data analysis </b>.\n",
        "\n",
        "[1.1] General\n",
        "- ProfileReport()\n",
        "- info()\n",
        "- value_count()\n",
        "- describe()\n",
        "- hist()\n",
        "\n",
        "[1.2] EDA\n",
        "\n",
        "- Visualize output: \n",
        "\n",
        "      .plot()\n",
        "- Correllation: \n",
        "        .corr()\n",
        "        .scatter_matrix()\n",
        "      \n",
        "[1.3] Attribute Combinations\n",
        "\n",
        "[2] <b> Data Cleaning </b>\n",
        "\n",
        "[2.1] Numerical variables\n",
        "\n",
        "[2.1.1] Missing data\n",
        "- Analyzing\n",
        "- dropna()\n",
        "- drop()\n",
        "- fillna()\n",
        "- SimpleImputer()\n",
        "\n",
        "[2.1.2] Outliers\n",
        "\n",
        "[2.1.3] Contaminated data\n",
        "\n",
        "[2.1.4] Invalid data\n",
        "\n",
        "[2.1.5] Duplicate data\n",
        "\n",
        "- drop_duplicate()\n",
        "\n",
        "\n",
        "[2.2] Categorical Variables\n",
        "\n",
        "[2.2.1] Encoder\n",
        "\n",
        "- OrdinalEncoder()\n",
        "- OneHotEncoder()\n",
        "\n",
        "[2.2.2] Inconsistent data\n",
        "\n",
        "[2.2.3] Datatype issues\n",
        "\n",
        "\n",
        "[2.4] Feature Scaling\n",
        "\n",
        "- MinMaxScaler()\n",
        "- StandardScaler()\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSFwfWGToV35"
      },
      "source": [
        "[To some Internal Section](#1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "VC2Pv048oV36",
        "outputId": "1c7d9b0c-3962-44a3-af87-c4144ea22b9b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas_profiling import  ProfileReport\n",
        "import numpy as np\n",
        "\n",
        "# Load data on github\n",
        "titanic_path = \"https://raw.githubusercontent.com/thanhtam98/Kaggle-machine-learnin-note/main/data/titanic/\"\n",
        "titanic_df_train = pd.read_csv(titanic_path + \"train.csv\")\n",
        "housing_path = \"https://raw.githubusercontent.com/thanhtam98/Kaggle-machine-learnin-note/main/data/housing/\"\n",
        "housing_df_train = pd.read_csv(housing_path + \"train.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-1xVk8fxBOa",
        "outputId": "2297ff39-78a7-463f-911e-399425f5aff0"
      },
      "outputs": [],
      "source": [
        "# Split num and cat\n",
        "titanic_df_train_num = titanic_df_train.select_dtypes(exclude=[\"object\"])\n",
        "titanic_df_train_cat = titanic_df_train.select_dtypes(exclude=[np.number])\n",
        "print(\"Titanic numberic \\n\" + str(titanic_df_train_num.head))\n",
        "print(\"Titanic categorical \\n\" + str(titanic_df_train_cat.head))\n",
        "\n",
        "housing_df_train_num = housing_df_train.select_dtypes(exclude=[\"object\"])\n",
        "housing_df_train_cat = housing_df_train.select_dtypes(exclude=[np.number])\n",
        "print(\"Housing numberic  \\n\" + str(housing_df_train_num.head))\n",
        "print(\"Housing categorical  \\n\" + str(housing_df_train_cat.head))\n",
        "\n",
        "\n",
        "# make housing data as main data\n",
        "df_train = housing_df_train\n",
        "df_train_num = housing_df_train_num\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiKIv_6coV37"
      },
      "source": [
        "## 1. Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g6h-lXpoV37"
      },
      "source": [
        "\n",
        "_Phải có cái nhìn tổng quan về giá trị output bên ngoài thực tiễn. Và chúng là người muốn hiểu biết về nó_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMxJPsfKoV38"
      },
      "source": [
        "### 1.1 General\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### pandas_profiling ProfileReport "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2UNBmdroV38",
        "outputId": "8923fdbc-b786-4b68-f31c-c458f5307297"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "titanic_df_train.head()\n",
        "profile = ProfileReport(\n",
        "    titanic_df_train, title=\"Pandas Profiling Report for Housing train dataset\"\n",
        "      )\n",
        "profile.to_file(\"pandas_profiling_example.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxNAC7bjoV3-"
      },
      "source": [
        "#### pandas support function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPXSEd9hoV3-",
        "outputId": "2abffb54-bedb-47b3-aaa9-9835be9207fc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "titanic_df_train.describe()\n",
        "titanic_df_train.info()\n",
        "titanic_df_train.value_counts()\n",
        "housing_df_train.describe()\n",
        "housing_df_train.hist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcpsTI_xoV3_"
      },
      "source": [
        "### 1.2 EDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualize output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kQRZG2MoV3_",
        "outputId": "398a938e-9d4e-4560-bd26-547e21516c8d"
      },
      "outputs": [],
      "source": [
        "# Matplotlib\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "df_train.head()\n",
        "df_train.hist(bins=50, figsize=(20, 15));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7623xNVJoV3_",
        "outputId": "c5f779ea-72b0-46ef-e296-77908695506d"
      },
      "outputs": [],
      "source": [
        "# Seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "sns.distplot(df_train['SalePrice']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PwX9VvXxBOg"
      },
      "source": [
        "#### Relationship and Correllation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL5xLYp-oV4A"
      },
      "source": [
        "##### Relationship with numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-hP8sPDoV4A",
        "outputId": "4b0467ae-cbde-4ec5-db56-cf18954178e8"
      },
      "outputs": [],
      "source": [
        "#scatter plot grlivarea/saleprice\n",
        "var = 'GrLivArea'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxxyNeWXoV4A"
      },
      "source": [
        "##### Relationship with  categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhpx2u2IoV4B",
        "outputId": "f77de4fe-4b2a-40a4-da9c-80688d5eee7e"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#box plot overallqual/saleprice\n",
        "var = 'OverallQual'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
        "fig.axis(ymin=0, ymax=800000);\n",
        "\n",
        "var = 'YearBuilt'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "f, ax = plt.subplots(figsize=(16, 8))\n",
        "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
        "fig.axis(ymin=0, ymax=800000);\n",
        "plt.xticks(rotation=90);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0mhOhS7oV4B"
      },
      "source": [
        "##### Correlation matrix heat map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2ZpeKDioV4B",
        "outputId": "3d61512a-c83b-4218-906b-c7b139093993"
      },
      "outputs": [],
      "source": [
        "#correlation matrix\n",
        "corrmat = df_train.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corrmat, vmax=.8, square=True);\n",
        "\n",
        "#Todo: detail, discard the lower correlation  variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFGV0v2cxBOi",
        "outputId": "d2f90034-945c-4e4a-a5dd-b95a786e945e"
      },
      "outputs": [],
      "source": [
        "# zoomed heatmap style\n",
        "\n",
        "k = 10 #number of variables for heatmap\n",
        "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
        "cm = np.corrcoef(df_train[cols].values.T)\n",
        "sns.set(font_scale=1.25)\n",
        "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qGOH_hCoV4B"
      },
      "source": [
        "##### Scatter plots\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EwNNQJXoV4B",
        "outputId": "e23cb9fb-6ca7-4653-e397-5a93f77943c9"
      },
      "outputs": [],
      "source": [
        "#scatterplot\n",
        "sns.set()\n",
        "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
        "sns.pairplot(df_train[cols], size = 2.5)\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqzOZBYJoV4C"
      },
      "source": [
        "## 2. Data clearning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Numerical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW4NJFN_oV4C"
      },
      "source": [
        "#### 2.1.1 Missing data:\n",
        "* How prevalent is the missing data?\n",
        "* Is missing data random or does it have a pattern?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-lzZ_XJoV4C"
      },
      "source": [
        "##### Analyzing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5rd48l7oV4C",
        "outputId": "3f5cf0be-340c-4484-fe76-e3c4eff55007"
      },
      "outputs": [],
      "source": [
        "# Todo: add more function to analyze data\n",
        "total = df_train.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZNXw6K7oV4D"
      },
      "source": [
        "##### Dealing with missing data (Missing data handling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmwAR3SSoV4D"
      },
      "source": [
        "- **Drop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vvVYYFLoV4D",
        "outputId": "7c5027ed-ce09-4246-85e9-a3495a411461"
      },
      "outputs": [],
      "source": [
        "#dealing with missing data\n",
        "df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
        "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
        "df_train.isnull().sum().max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZKhyUaboV4D"
      },
      "source": [
        "- **Dropna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw5njb5axBOm"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.dropna()\n",
        "df_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IibDRm9OxBOm"
      },
      "source": [
        "- **Fillna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDVl-ZUMxBOm"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSmojvItoV4D"
      },
      "source": [
        "- Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAvj_0OmoV4D"
      },
      "outputs": [],
      "source": [
        "from re import S\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "my_imputer = SimpleImputer(strategy=\"most_frequent\") # most_frequent, mean, median, constant\n",
        "df_train_imputed = pd.DataFrame(my_imputer.fit_transform(df_train_num))\n",
        "df_train_imputed.columns = df_train_num.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "758vZ4GUxBOn",
        "outputId": "d5574cda-7e47-41dc-fa14-24fc260a4087"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: COMPATE BEFORE AND AFTER IMPUTATION\n",
        "\n",
        "# Define figure parameters\n",
        "sns.set(rc={\"figure.figsize\": (14, 12)})\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axes = plt.subplots(2, 2)\n",
        "\n",
        "# Plot the results\n",
        "for feature, fig_pos in zip([\"LotFrontage\", \"MasVnrArea\"], [0, 1]):\n",
        "    \"\"\"Features distribution before and after imputation\"\"\"\n",
        "    # before imputation\n",
        "    p = sns.histplot(ax=axes[fig_pos, 0], x=df_train_num[feature],\n",
        "                     kde=True, bins=30, color=\"dodgerblue\", edgecolor=\"black\")\n",
        "    p.set_ylabel(f\"Before imputation\", fontsize=14)\n",
        "    # after imputation\n",
        "    q = sns.histplot(ax=axes[fig_pos, 1], x=df_train_imputed[feature],\n",
        "                     kde=True, bins=30, color=\"firebrick\", edgecolor=\"black\")\n",
        "    q.set_ylabel(f\"After imputation\", fontsize=14)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlwIwCEqoV4E"
      },
      "source": [
        "#### 2.1.2 Outlier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtSrOPwIoV4E"
      },
      "source": [
        "##### Univariate analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lgAQUP7oV4E"
      },
      "source": [
        "- Standardizing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYAk53hKoV4E"
      },
      "outputs": [],
      "source": [
        "\n",
        "#standardizing data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "saleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\n",
        "low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\n",
        "high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\n",
        "print('outer range (low) of the distribution:')\n",
        "print(low_range)\n",
        "print('\\nouter range (high) of the distribution:')\n",
        "print(high_range)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwumEkzBoV4E"
      },
      "source": [
        "##### Bivariate analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlwIwCEqoV4E"
      },
      "source": [
        "#### 2.1.3  Contaminated data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlwIwCEqoV4E"
      },
      "source": [
        "#### 2.1.4 Invalid data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlwIwCEqoV4E"
      },
      "source": [
        "#### 2.1.5 Duplicate data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Categorical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.1 Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9SvAjxKxBOn"
      },
      "source": [
        "- **OrdinalEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNSooWV3xBOn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onhz6eQVxBOn"
      },
      "source": [
        "- **OneHotEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_UVjVhZxBOo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpwkbeM8oV4E"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.2 Inconsistent data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.3 Datatype issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbQMbapvoV4F"
      },
      "source": [
        "### 2.3 Quasi-Constant variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYjnpLe7oV4F"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "# 0.05: drop column where 95% of the values are constant\n",
        "sel = VarianceThreshold(threshold=0.05) \n",
        "# fit finds the features with constant variance\n",
        "sel.fit(df_train_num.iloc[:, :-1])\n",
        "# Get the number of features that are not constant\n",
        "print(f\"Number of retained features: {sum(sel.get_support())}\")\n",
        "\n",
        "print(f\"\\nNumber of quasi_constant features: {len(df_train_num.iloc[:, :-1].columns) - sum(sel.get_support())}\")\n",
        "\n",
        "quasi_constant_features_list = [x for x in df_train_num.iloc[:, :-1].columns if x not in df_train_num.iloc[:, :-1].columns[sel.get_support()]]\n",
        "\n",
        "print(f\"\\nQuasi-constant features to be dropped: {quasi_constant_features_list}\")\n",
        "# Let's drop these columns from df_train_num\n",
        "df_train_num.drop(quasi_constant_features_list, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh0Fty6voV4F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5nJ0EBfoV4F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xQEe-BAxBOq"
      },
      "source": [
        "## 3. Feature transform and scaling "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1NNvg39xBOq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "197VIbu1xBOr"
      },
      "source": [
        "## 4. Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6kWTcajxBOr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !jupyter nbconvert --to html note.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !jupyter nbconvert --to pdf note.ipynb"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "note.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
